{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "marvin_cell": "acquisitor"
   },
   "outputs": [],
   "source": [
    "#Data Acquisitor\n",
    "import findspark\n",
    "import tempfile\n",
    "import numpy as np\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Building SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "   \n",
    "sc = spark.sparkContext\n",
    "\n",
    "from marvin_python_toolbox.common.data import MarvinData\n",
    "\n",
    "file_path = MarvinData.download_file(url=\"https://s3.amazonaws.com/marvin-engines-data/Iris.csv\")\n",
    "\n",
    "iris_df = spark.read.csv(file_path, header=\"true\")\n",
    "\n",
    "marvin_initial_dataset = iris_df.drop(\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "marvin_cell": "tpreparator"
   },
   "outputs": [],
   "source": [
    "#Training Preparator\n",
    "\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "l_atributos = [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]\n",
    "\n",
    "dataset = marvin_initial_dataset\n",
    "\n",
    "\n",
    "#Chaniging atribute types to double\n",
    "for coluna in l_atributos:\n",
    "    dataset = dataset.withColumn(coluna, dataset[coluna].cast(DoubleType()))\n",
    "    \n",
    "    \n",
    "#Maping column \"Species\" to a numerical value in a new collumn named \"label\"\n",
    "label_indexer = StringIndexer().setInputCol(\"Species\").setOutputCol(\"label\")\n",
    "\n",
    "dataset = label_indexer.fit(dataset).transform(dataset)\n",
    "\n",
    "\n",
    "#Concatenating all features into a single vector and naming the resulting column as \"features\" \n",
    "assembler = VectorAssembler(inputCols=[\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"],outputCol=\"features\")\n",
    "dataset = assembler.transform(dataset)\n",
    "\n",
    "\n",
    "(train, test) = dataset.randomSplit([0.7, 0.3])\n",
    "\n",
    "marvin_dataset = {'train': train, 'test': test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "marvin_cell": "trainer",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Model Training\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "\n",
    "nb = NaiveBayes()\n",
    "\n",
    "pipeline = Pipeline().setStages([nb])\n",
    "\n",
    "marvin_model = pipeline.fit(marvin_dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "marvin_cell": "evaluator",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Model Evaluation\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "\n",
    "predictions = marvin_model.transform(marvin_dataset['test'])\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "marvin_metrics = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = [5.8, 2.7, 5.1, 1.9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "marvin_cell": "ppreparator"
   },
   "outputs": [],
   "source": [
    "input_message = input_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "marvin_cell": "predictor"
   },
   "outputs": [],
   "source": [
    "#Predictor\n",
    "\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Building SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"local\") \\\n",
    "   .appName(\"Spark MLlib\") \\\n",
    "   .config(\"spark.executor.memory\", \"1gb\") \\\n",
    "   .getOrCreate()\n",
    "   \n",
    "sc = spark.sparkContext\n",
    "\n",
    "\n",
    "field = [StructField(\"SepalLengthCm\", FloatType(), True), StructField(\"SepalWidthCm\", FloatType(), True), StructField(\"PetalLengthCm\", FloatType(), True), StructField(\"PetalWidthCm\", FloatType(), True)]\n",
    "\n",
    "input_schema = StructType(field)\n",
    "\n",
    "input_message = [input_message]\n",
    "\n",
    "input_message = spark.createDataFrame(input_message, schema=input_schema)\n",
    "\n",
    "colunas = [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]\n",
    "\n",
    "for coluna in colunas:\n",
    "    input_message = input_message.withColumn(coluna, input_message[coluna].cast(FloatType()))\n",
    "    \n",
    "assembler = VectorAssembler(inputCols=[\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"],outputCol=\"features\")\n",
    "input_message = assembler.transform(input_message)\n",
    "\n",
    "\n",
    "final_prediction = marvin_model.transform(input_message)\n",
    "\n",
    "final_prediction = final_prediction.select('prediction').collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
